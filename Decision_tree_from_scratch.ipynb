{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader\n",
    "from math import *\n",
    "\n",
    "# Load a CSV file\n",
    "def csv_import(filename):\n",
    "\tfile_open = open(filename)\n",
    "\tl = reader(file_open)\n",
    "\tdf = list(l)\n",
    "\treturn df\n",
    "\n",
    "\n",
    "# get_split a dataframe into k folds\n",
    "def k_fold_get_split(dataframe, k_folds):\n",
    "\tdataframe_get_split = list()\n",
    "\tdataframe_copy = list(dataframe)\n",
    "\tfold_size = int(len(dataframe) / k_folds)\n",
    "\tfor i in range(k_folds):\n",
    "\t\tfold = list()\n",
    "\t\twhile len(fold) < fold_size:\n",
    "\t\t\tindex = randrange(len(dataframe_copy))\n",
    "\t\t\tfold.append(dataframe_copy.pop(index))\n",
    "\t\tdataframe_get_split.append(fold)\n",
    "\treturn dataframe_get_split\n",
    "\n",
    "# Calculate accuracy of the model\n",
    "def accuracy_score(actual, predicted):\n",
    "\ttrue = 0\n",
    "\tfor i in range(len(actual)):\n",
    "\t\tif actual[i] == predicted[i]:\n",
    "\t\t\ttrue += 1\n",
    "\treturn true / float(len(actual)) * 100.0\n",
    "\n",
    "# Evaluate decision tree using a cross validation get_split\n",
    "def dt_implement(dataframe, algorithm, k_folds, *args):\n",
    "\tfolds = k_fold_get_split(dataframe, k_folds)\n",
    "\tscores = list()\n",
    "\tfor fold in folds:\n",
    "\t\ttrain_set = list(folds)\n",
    "\t\ttrain_set.remove(fold)\n",
    "\t\ttrain_set = sum(train_set, [])\n",
    "\t\ttest_set = list()\n",
    "\t\tfor rows in fold:\n",
    "\t\t\trows_copy = list(rows)\n",
    "\t\t\ttest_set.append(rows_copy)\n",
    "\t\t\trows_copy[-1] = None\n",
    "\t\tpredicted = algorithm(train_set, test_set, *args)\n",
    "\t\tactual = [rows[-1] for rows in fold]\n",
    "\t\taccuracy = accuracy_score(actual, predicted)\n",
    "\t\tscores.append(accuracy)\n",
    "\treturn scores\n",
    "\n",
    "# split a dataframe based on feature and feature value\n",
    "def get_split_node(index, value, dataframe):\n",
    "\tleft_side, right_side = list(), list()\n",
    "\tfor rows in dataframe:\n",
    "\t\tif rows[index] < value:\n",
    "\t\t\tleft_side.append(rows)\n",
    "\t\telse:\n",
    "\t\t\tright_side.append(rows)\n",
    "\treturn left_side, right_side\n",
    "\n",
    "# Calculate the entropy index for a get_split dataframe\n",
    "def entropy_index(groups, classes):\n",
    "    total_instances = float(sum([len(group) for group in groups]))\n",
    "    #print(\"total number of instances\", total_instances)\n",
    "    \n",
    "    entropy = 0.0\n",
    "    for group in groups:\n",
    "        size=float(len(group))\n",
    "        #print(\"size of groups is\", group, size)\n",
    "        #avoid divide by zero\n",
    "        if size==0:\n",
    "            continue\n",
    "        score=0\n",
    "        # score the group based on the score for each class\n",
    "        for class_val in classes:\n",
    "            p = ([row[-1] for row in group].count(class_val)) / size \n",
    "            #print(p)\n",
    "            if p <=0:\n",
    "                score=0\n",
    "            else:\n",
    "                score = -1*(p *log(p,2))\n",
    "            score = score+score\n",
    "            #print(\"score\",score)\n",
    "        entropy += score * (size / total_instances)\n",
    "    return entropy\n",
    "\n",
    "# Select the best split for a dataframe\n",
    "def best_get_split(dataframe):\n",
    "\tclass_values = list(set(rows[-1] for rows in dataframe))\n",
    "\ttree_index, tree_value, tree_score, tree_groups = 9999, 9999, 9999, None\n",
    "\tfor index in range(len(dataframe[0])-1):\n",
    "\t\tfor rows in dataframe:\n",
    "\t\t\tgroups = get_split_node(index, rows[index], dataframe)\n",
    "\t\t\tentropy = entropy_index(groups, class_values)\n",
    "\t\t\tif entropy < tree_score:\n",
    "\t\t\t\ttree_index, tree_value, tree_score, tree_groups = index, rows[index], entropy, groups\n",
    "\treturn {'index':tree_index, 'value':tree_value, 'groups':tree_groups}\n",
    "\n",
    "# Create a terminal node value\n",
    "def terminal_node(group):\n",
    "\toutput = [rows[-1] for rows in group]\n",
    "\treturn max(set(output), key=output.count)\n",
    "\n",
    "# Create child get_splits for a node or make terminal\n",
    "def get_split(node, max_depth, min_size, depth):\n",
    "\tleft_side, right_side = node['groups']\n",
    "\tdel(node['groups'])\n",
    "\t# check for a no split\n",
    "\tif not left_side or not right_side:\n",
    "\t\tnode['left_side'] = node['right_side'] = terminal_node(left_side + right_side)\n",
    "\t\treturn\n",
    "\t# check for maximum depth\n",
    "\tif depth >= max_depth:\n",
    "\t\tnode['left_side'], node['right_side'] = terminal_node(left_side), terminal_node(right_side)\n",
    "\t\treturn\n",
    "\t# process left_side child\n",
    "\tif len(left_side) <= min_size:\n",
    "\t\tnode['left_side'] = terminal_node(left_side)\n",
    "\telse:\n",
    "\t\tnode['left_side'] = best_get_split(left_side)\n",
    "\t\tget_split(node['left_side'], max_depth, min_size, depth+1)\n",
    "\t# process right_side child\n",
    "\tif len(right_side) <= min_size:\n",
    "\t\tnode['right_side'] = terminal_node(right_side)\n",
    "\telse:\n",
    "\t\tnode['right_side'] = best_get_split(right_side)\n",
    "\t\tget_split(node['right_side'], max_depth, min_size, depth+1)\n",
    "\n",
    "# Build a decision tree\n",
    "def tree_building(train, max_depth, min_size):\n",
    "\troot = best_get_split(train)\n",
    "\tget_split(root, max_depth, min_size, 1)\n",
    "\treturn root\n",
    "\n",
    "# Do prediction with a decision tree\n",
    "def predict_dt(node, rows):\n",
    "\tif rows[node['index']] < node['value']:\n",
    "\t\tif isinstance(node['left_side'], dict):\n",
    "\t\t\treturn predict_dt(node['left_side'], rows)\n",
    "\t\telse:\n",
    "\t\t\treturn node['left_side']\n",
    "\telse:\n",
    "\t\tif isinstance(node['right_side'], dict):\n",
    "\t\t\treturn predict_dt(node['right_side'], rows)\n",
    "\t\telse:\n",
    "\t\t\treturn node['right_side']\n",
    "\n",
    "# Tree Algorithm\n",
    "def dt(train, test, max_depth, min_size):\n",
    "\ttree = tree_building(train, max_depth, min_size)\n",
    "\tprediction = list()\n",
    "\tfor rows in test:\n",
    "\t\tpredict_dtion = predict_dt(tree, rows)\n",
    "\t\tprediction.append(predict_dtion)\n",
    "\treturn(prediction)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree on wine dataset with 10 fold cross validation (entropy)\n",
    "seed(3250)\n",
    "# load and prepare data\n",
    "filename = 'wine-dataset.csv'\n",
    "dataframe = csv_import(filename)\n",
    "k_folds = 10\n",
    "max_depth = 5\n",
    "min_size = 10\n",
    "scores = dt_implement(dataframe, dt, k_folds, max_depth, min_size)\n",
    "print('Scores using Entropy: %.4f%%' % scores)\n",
    "print('Mean Accuracy using Entropy: %.4f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the gini index for a get_split dataframe\n",
    "def gini_index(groups, classes):\n",
    "    total_instances = float(sum([len(group) for group in groups]))\n",
    "    #print(\"total number of instances\", total_instances)\n",
    "    \n",
    "    gini = 0.0\n",
    "    for group in groups:\n",
    "        size=float(len(group))\n",
    "        #print(\"size of groups is\", group, size)\n",
    "        #avoid divide by zero\n",
    "        if size==0:\n",
    "            continue\n",
    "        score=0\n",
    "        # score the group based on the score for each class\n",
    "        for class_val in classes:\n",
    "            p = ([row[-1] for row in group].count(class_val)) / size \n",
    "\n",
    "            score = p*p\n",
    "            #print(\"score\",score)\n",
    "        gini += (1-score) * (size / total_instances)\n",
    "    return gini\n",
    "\n",
    "# Select the best get_split for a dataframe\n",
    "def best_get_split_gini(dataframe):\n",
    "\tclass_values = list(set(rows[-1] for rows in dataframe))\n",
    "\ttree_index, tree_value, tree_score, tree_groups = 9999, 9999, 9999, None\n",
    "\tfor index in range(len(dataframe[0])-1):\n",
    "\t\tfor rows in dataframe:\n",
    "\t\t\tgroups = get_split_node(index, rows[index], dataframe)\n",
    "\t\t\tgini = gini_index(groups, class_values)\n",
    "\t\t\tif gini < tree_score:\n",
    "\t\t\t\ttree_index, tree_value, tree_score, tree_groups = index, rows[index], gini, groups\n",
    "\treturn {'index':tree_index, 'value':tree_value, 'groups':tree_groups}\n",
    "\n",
    "# Build a decision tree\n",
    "def tree_building_gini(train, max_depth, min_size):\n",
    "\troot = best_get_split_gini(train)\n",
    "\tget_split(root, max_depth, min_size, 1)\n",
    "\treturn root\n",
    "\n",
    "# Evaluate decision tree using a cross validation get_split\n",
    "def dt_implement(dataframe, algorithm, k_folds, *args):\n",
    "\tfolds = k_fold_get_split(dataframe, k_folds)\n",
    "\tscores = list()\n",
    "\tfor fold in folds:\n",
    "\t\ttrain_set = list(folds)\n",
    "\t\ttrain_set.remove(fold)\n",
    "\t\ttrain_set = sum(train_set, [])\n",
    "\t\ttest_set = list()\n",
    "\t\tfor rows in fold:\n",
    "\t\t\trows_copy = list(rows)\n",
    "\t\t\ttest_set.append(rows_copy)\n",
    "\t\t\trows_copy[-1] = None\n",
    "\t\tpredicted = algorithm(train_set, test_set, *args)\n",
    "\t\tactual = [rows[-1] for rows in fold]\n",
    "\t\taccuracy = accuracy_score(actual, predicted)\n",
    "\t\tscores.append(accuracy)\n",
    "\treturn scores\n",
    "\n",
    "# Tree Algorithm\n",
    "def dt_gini(train, test, max_depth, min_size):\n",
    "\ttree = tree_building_gini(train, max_depth, min_size)\n",
    "\tprediction = list()\n",
    "\tfor rows in test:\n",
    "\t\tpredict_dtion = predict_dt(tree, rows)\n",
    "\t\tprediction.append(predict_dtion)\n",
    "\treturn(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree on wine dataset with 10 fold cross validation (gini)\n",
    "seed(3250)\n",
    "# load and prepare data\n",
    "filename = 'wine-dataset.csv'\n",
    "dataframe = csv_import(filename)\n",
    "k_folds = 10\n",
    "max_depth = 5\n",
    "min_size = 10\n",
    "scores = dt_implement(dataframe, dt_gini, k_folds, max_depth, min_size)\n",
    "print('Scores using Gini: %.4f%%' % scores)\n",
    "print('Mean Accuracy using Gini: %.4f%%' % (sum(scores)/float(len(scores))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
